[Overview](#overview) | [Documentation](documentation.md) | [Video](#video) | [Publications](#workshops-presentations-papers) | [Team](#team) | [Web Editor](http://app.embodiedcode.net/users/login)

![Image](assets/xrdesign_logo.png)
# Overview

The increasing sophistication and availability of Augmented and Virtual Reality
(AR/VR) technologies wield the potential to transform how we teach and learn computational
concepts and coding. This project develops a platform for creative coding in virtual
and augmented reality. The Embodied Coding Environment (ECE) is a node-based system developed in the
Unity game engine. It is conceptualized as a merged digital/physical workspace where spatial
representations of code, the visual outputs of the code, and user editing histories are
co-located in a virtual 3D space.

It has been theorized that learners’ abilities to understand and reason about functions,
algorithms, conditionals, and other abstract computational concepts stem in part from more
fundamental sensori-motor and perceptual experiences of the physical world. Our own work, for
instance, has revealed that computer science (CS) educators incorporate a wide range of
metaphors grounded in tangible experience into their lessons on computational concepts, such as
demonstrating sorting algorithms with a deck of cards or the transfer of information between
functions by throwing paper airplanes. Our long-term research aims center on the question of
how a coding platform that supports these types of embodied conceptual phenomena can make
learning to code become a more intuitive process.

# Getting Started

Follow our [Getting Started Guide](docs/getting-started.md) to run the app on you headset. 

# Video
<div class="embed-youtube">
<iframe width="560" height="315" src="https://www.youtube.com/embed/NVKId7Qmf_4?si=evDF5UjZ9kJ08b0L" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
 </div>

Video Documentation for SIGCSE 2024. Video by Reid Brockmeier and Kylie Muller.
 
# Workshops, Presentations, Papers
- Lay, R.; Bhutada, R.; Lobo, A.; Twomey, R.; Eguchi, A.; Wu, Y.; “Embodied Code: Creative Coding in Virtual Reality”, SIGCSE TS 2024 (55th ACM Technical Symposium on Computer Science Education)
- Wu, Y. C., Sharkey, T., and Wood, T. (2023). “Designing the embodied coding environment: A platform inspired by educators and learners.” (https://circls.org/partnerships-for-change) CIRCLS Rapid Community Report
- "An Immersive Environment for Embodied Code", 2022 ACM Conference on Human Factors in Computing Systems, CHI'22 ([interactivity workshop](https://programs.sigchi.org/chi/2022/program/content/72166) and [extended abstract](https://dl.acm.org/doi/abs/10.1145/3491101.3519896))
- ["Need Finding for an Embodied Coding Platform: Educators’ Practices and Perspectives"](https://www.scitepress.org/PublicationsDetail.aspx?ID=OhB4jK63WSU=&t=1), 14th International Conference on Computer Supported Education, CSEDU 2022 (paper)
- [San Diego Computer Science Teachers Association](https://www.youtube.com/watch?v=oZYu1BHwKpI), November 18, 2021 (demo)
- [UCSD Design Innovation Building Dedication](https://www.youtube.com/watch?v=-QucxZofqvs), November 18, 2021 (demo)
- [_Exploring Virtual Reality and Embodied Computational Reasoning_](icer/README.md) 17th annual ACM International Computing Education Research Conference, ICER 2021, Saturday August 14, 2021 (workshop)
- [_Embodied Coding in Augmented Reality_](https://videohall.com/p/2000), 2021 NSF STEM for All Video Showcase (video)
- "How are computational concepts learned and taught? A thematic analysis study informing the design of an Augmented Reality coding platform", 13th International Conference on Computer Supported Education, CSEDU 2021, 23-25 April, 2021 (poster and abstract)
- Study: [_Spring Break Research Experience_](sbre/README.md), UC San Diego, March 2021

# Team
- Ying Wu, PI [insight.ucsd.edu](https://insight.ucsd.edu)
- Robert Twomey, co-PI [roberttwomey.com](https://roberttwomey.com)
- Monica Sweet, Investigator [UCSD CREATE](https://create.ucsd.edu/about/people/index.html#Research-&-Evaluation)
- Amy Eguchi, Investigator [UCSD EDS](https://eds.ucsd.edu/discover/people/faculty/eguchi.html)
- Rhea Bhutada
- Alejandro Lobo
- Ryan Lay
- Reid Brockmeier
- Kylie Muller

# Alumni
- Timothy Wood, Postdoc [fishuyo.com](http://fishuyo.com/)
- Tommy Sharkey, Grad Researcher [tlsharkey.com](https://www.tlsharkey.com/)

# Contact
To learn more, contact PI Ying Wu at [ycwu@ucsd.edu](mailto:ycwu@ucsd.edu)

# Participating Labs

- [insight.ucsd.edu](https://insight.ucsd.edu)
- [imagination.ucsd.edu](http://imagination.ucsd.edu)
- [hxi.ucsd.edu](http://hxi.ucsd.edu/)
- [cohab-lab.net](http://cohab-lab.net)

# Support

This work is supported by the National Science Foundation under [Grant #2017042](https://nsf.gov/awardsearch/showAward?AWD_ID=2017042)
